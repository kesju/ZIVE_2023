{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriptas sukuria zive duomenų analogą iš MIT duomenų, į sub-aplanką rec_dir įrašomi\n",
    "# transformuoti EKG įrašai *.npy ir anotacijų failai *.json.\n",
    "# Išeities duomenys MIT_BIH atsisiunčiami iš aplanko mit-bih-arrhythmia-database-1.0.0\n",
    "# https://archive.physionet.org/physiobank/database/html/mitdbdir/mitdbdir.htm\n",
    "# The recordings were digitized at 360 samples per second per channel with 11-bit\n",
    "# resolution over a 10 mV range. In most records, the upper signal (channel 0) is\n",
    "# a modified limb lead II (MLII), obtained by placing the electrodes on the chest.\n",
    "\n",
    "# Iš MIT reaguojame tik į anotacijas N,L,R,e,j,V,E,S,A,a,J,F,Q, visas kitas ignoruojame.\n",
    "# MIT2ZIVE duomenyse paliekame tik makroanotacijas: N,S,V,F,U. \n",
    "\n",
    "# Failai skaldomi į 3 dalis, recordId = 1,2,3, kad būtų panašaus ilgio, kauip Zive įrašai.\n",
    "\n",
    "# Programos planas:\n",
    "# Nuskaitome MIT-BIH ekg įrašą: channel = 0, skaitome mlvoltus\n",
    "# Anotacijų mapingas į N,V,S,F,U\n",
    "# Pakeičiame diskretizavimo dažnį iš 360 į 200 Hz\n",
    "# Perskaičiuojame anotacijos vietas\n",
    "# Padalijame įrašus į tris dalis\n",
    "# Įrašome ekg ir anotacijas zive formatu į diską\n",
    "# Suformuojame comments.csv failą, kuriame komentaruose nurodysime DS1, ar DS2 \n",
    "\n",
    "# //////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "# Waveform Database Software Package (WFDB) for Python\n",
    "# https://physionet.org/content/wfdb-python/4.1.0/\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from neurokit2 import signal_resample\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "# from zive_util_vu import create_dir\n",
    "from mit_bih_util import create_dir\n",
    "\n",
    "def make_dict_array(atr_sample, atr_symbol):\n",
    "    array_of_dict = []\n",
    "    for sample, symbol in zip(atr_sample, atr_symbol):\n",
    "        d = {'sample': sample, 'symbol': symbol}\n",
    "        array_of_dict.append(d)\n",
    "    return array_of_dict   \n",
    "\n",
    "def print_dict_array(dict_array, incl = []):\n",
    "    for d in dict_array:\n",
    "        sample = d['sample']\n",
    "        symbol = d['symbol']\n",
    "        if bool(incl) == False:\n",
    "            if (symbol != 'N'):\n",
    "                print(f\"Sample: {sample}, Symbol: {symbol}\")    \n",
    "        else:\n",
    "            if (symbol in incl):\n",
    "                print(f\"Sample: {sample}, Symbol: {symbol}\")     \n",
    "\n",
    "def zive_read_file_1ch(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    a = np.fromfile(f, dtype=np.dtype('>i4'))\n",
    "    ADCmax=0x800000\n",
    "    Vref=2.5\n",
    "    b = (a - ADCmax/2)*2*Vref/ADCmax/3.10*1000\n",
    "    ecg_signal = b - np.mean(b)\n",
    "    return ecg_signal\n",
    "\n",
    "def zive_read_df_rpeaks(db_path, file_name):\n",
    "    file_path = Path(db_path, file_name + '.json')\n",
    "    with open(file_path,'r', encoding=\"utf8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    df_rpeaks = pd.json_normalize(data, record_path =['rpeaks'])\n",
    "    return df_rpeaks\n",
    "\n",
    "def get_noise_spans(atr_sample, atr_symbol):\n",
    "    occurrences = [i for i in range(len(atr_symbol)) if atr_symbol[i] == '~']\n",
    "    # print(occurrences)\n",
    "    pairs = []\n",
    "    for i in range(0, len(occurrences), 2):\n",
    "        if i+1 < len(occurrences):\n",
    "            startIndex = atr_sample[occurrences[i]]\n",
    "            endIndex = atr_sample[occurrences[i+1]]\n",
    "            pairs.append({'startIndex': int(startIndex), 'endIndex': int(endIndex)})\n",
    "    return pairs\n",
    "\n",
    "\n",
    "print(\"\\nSukuriamas Zive duomenų analogas iš MIT duomenų\")\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\\\DI\\\\DUOM_2022_RUDUO'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/DUOMENU_TVARKYMAS_2023'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Aplankas su MIT-BIH duomenų rinkiniu\n",
    "db_folder_mit = 'mit-bih-arrhythmia-database-1.0.0'\n",
    "\n",
    "#  Aplankas, kur rašome MIT2ZIVE duomenis\n",
    "db_folder_mit2zive = 'records_npy_tst'\n",
    "\n",
    "\n",
    "# Užduodamas pacientų įrašų sąrašas\n",
    "# Testavimui\n",
    "records_nr = np.array([116])\n",
    "# records_nr = np.array([124,209,228])\n",
    "\n",
    "records_nr = np.array(\n",
    "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124,\n",
    "200, 201, 202, 203, 205, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231,\n",
    "232, 233, 234])\n",
    "\n",
    "records_nr = np.array([116])\n",
    "\n",
    "# MIT_BIH duomenų diskretizavimo dažnumas\n",
    "fs_mit = 360\n",
    "\n",
    "\n",
    "\n",
    "# ////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Nuoroda į MIT-BIH duomenų rinkinį\n",
    "db_path_mit = Path(Duomenu_aplankas, db_folder_mit)\n",
    "\n",
    "print(\"Bendras Zive duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"MIT duomenų aplankas: \", db_folder_mit)\n",
    "print(\"Pacientų įrašų sąrašas:\\n\",records_nr)\n",
    "print(\"Aplankas, kur rašome MIT2ZIVE duomenis:\\n\", db_folder_mit2zive)\n",
    "\n",
    "print(\"Pastaba: įrašai su nr. 102, 104, 107, ir 217 yra gauti iš pacientų su pacemakers ir yra praleisti\")\n",
    "print(\"207 paciento įrašas turi segmentus su ventricular flutter or fibrillation VF\")\n",
    "print(\"\\nDiskretizavimo dažnis fs_mit: \", fs_mit)\n",
    "\n",
    "\n",
    "# //////////////// Nurodomi MIT2ZIVE parametrai ////////////////////////////////\n",
    "\n",
    "\n",
    "# MIT2ZIVE duomenų diskretizavimo dažnumas\n",
    "fs_zive = 200 # diskretizavimo dažnumas\n",
    "\n",
    "# Neignoruojamų anotacijų sąrašas\n",
    "annot_list = ['N','L','R','e','j','A','a','J','S','V','E','F','Q','~']\n",
    "\n",
    "# Failai pūpsnių makro anotacijų formavimui\n",
    "annot_grouping = {\n",
    "'N':'N','R':'N', 'L':'N', 'e':'N', 'j':'N', 'A':'S','a':'S', 'J':'S', 'S':'S', 'V':'V', 'E':'V', 'F':'F','Q':'U', '~':'~' }\n",
    "\n",
    "\n",
    "selected_beats = {'N':0, 'S':1, 'V':2, 'F':3, 'U':4}\n",
    "\n",
    "# ////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Nuoroda į MIT2ZIVE duomenų rinkinį\n",
    "# db_path_mit2zive = Path(Duomenu_aplankas, db_folder_mit2zive)\n",
    "\n",
    "# Nuoroda į aplanką MIT2ZIVE EKG įrašams (.npy) ir anotacijoms (.json)\n",
    "rec_dir = Path(Duomenu_aplankas, db_folder_mit2zive)\n",
    "\n",
    "sant = fs_zive/fs_mit\n",
    "\n",
    "print(\"\\nAplankas transformuotiems duomenims: \", db_folder_mit2zive)\n",
    "\n",
    "# Sukūriame aplanką transformuotiems iš MIT į Zive formatą duomenims\n",
    "create_dir(rec_dir)\n",
    "\n",
    "print(\"Diskretizavimo dažnis fs_zive: \", fs_zive)\n",
    "print(f\"fs_zive/fs_mit = {sant:.2f}\")\n",
    "\n",
    "print(\"Paliekamos įrašuose anotacijos:\", annot_list)\n",
    "print(\"Failas grupavimui į makroanotacijas:\", annot_grouping)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ciklas per pacientų įrašus\n",
    "for record_nr in records_nr:\n",
    "\n",
    "# ----------------------------------------------- Nuskaitome įrašą\n",
    "    subject_path = f'{db_path_mit}/{record_nr}'\n",
    "    # ic(subject_path)\n",
    "\n",
    "    # Įrašo skaitymo variantai\n",
    "    # sequence, fields = wfdb.rdsamp(subject_path, channels=[0])\n",
    "    # record = wfdb.rdrecord('sample-data/a103l')\n",
    "\n",
    "    # https://www.programmersought.com/article/28613723297/\n",
    "    \n",
    "     # Variantas 1 - skaitmeninės reikšmės\n",
    "    # record = wfdb.rdrecord(subject_path, sampfrom=1,\n",
    "    #                             channels=[0], physical=False)\n",
    "    # sign_raw = record.d_signal[:,0]\n",
    "\n",
    "    # Variantas 2 - fizinės reikšmės - perverstos į mV\n",
    "    \n",
    "    record = wfdb.rdrecord(subject_path, sampfrom=0,channels=[0], physical=True)\n",
    "    signl_raw = record.p_signal[:,0]\n",
    "    # print(sign_raw[:20])\n",
    "\n",
    "    # https://wfdb.readthedocs.io/en/latest/wfdb.html\n",
    "\n",
    "    len_signl_raw = signl_raw.shape[0]\n",
    "    print(\"\\n\")\n",
    "    print(f\"Pacientas iš MIT: {record_nr}  Reikšmių: {len_signl_raw}\")\n",
    "\n",
    "    # Eilutės galimam filtravimui\n",
    "    # sign_transf = sign_raw\n",
    "    # sign_transf = signal_filter(signal=sign_raw, sampling_rate=360,\n",
    "    #  lowcut=0.1, method=\"butterworth\", order=5)\n",
    "\n",
    "    # Nuskaitome originalaus įrašo anotacijas\n",
    "    # https://wfdb.readthedocs.io/en/latest/wfdb.html \n",
    "    ann = wfdb.rdann(subject_path, 'atr', sampfrom=0, sampto=None, shift_samps=False)\n",
    "    atr_sample_org = ann.sample\n",
    "    atr_symbol_org = np.array(ann.symbol)\n",
    "\n",
    "    print(\"\\nAnotacijų pasiskirstymas originale:\")\n",
    "    smb_lst = Counter(atr_symbol_org)\n",
    "    print(dict(smb_lst))\n",
    "    print()\n",
    "    # smb_lst = Counter(atr_symbol)\n",
    "    # print(\"\\nOriginalių anotacijų pasiskirstymas:\")\n",
    "    # print(smb_lst)\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample,atr_symbol)\n",
    "    # print_dict_array(dict_array)\n",
    "\n",
    "\n",
    "# ------------------------------------ Resampling iš 360 Hz (MIT) į 200 Hz (Zive)\n",
    "    signl = signal_resample(signl_raw, sampling_rate=fs_mit,\n",
    "                              desired_sampling_rate=200, method=\"numpy\")\n",
    "    # https://neurokit2.readthedocs.io/en/latest/_modules/neurokit2/signal/signal_resample.html\n",
    "\n",
    "    signl_len = signl.shape[0]\n",
    "    print(f\"Pacientas Zive rinkiniui: {record_nr}  Resamplintas. Reikšmių: {signl_len}\")\n",
    "\n",
    "    # print(signl[:20])\n",
    "\n",
    "    # Resampliname anotacijų vietas\n",
    "    atr_sample_org = (atr_sample_org*sant).astype(int)\n",
    "\n",
    "    print(\"\\nAnotacijų pasiskirstymas po resampling:\")\n",
    "    smb_lst = Counter(atr_symbol_org)\n",
    "    print(dict(smb_lst))\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample,atr_symbol)\n",
    "    # print_dict_array(dict_array, incl = ['~'])\n",
    "\n",
    "# ------------------------------------------------- Sukūriame makro anotacijas\n",
    "    # Paliekame tik užduotas anotacijas iš annot_list, visas kitas (tarnybines)\n",
    "    # išvalome, išskyrus `~`, jas išvalysime vėliau \n",
    "    # Tarnybinės yra: '+', ir visos kitos\n",
    "    \n",
    "    atr_sample_n = []\n",
    "    atr_symbol_n = []\n",
    "    for i in range(atr_sample_org.shape[0]):\n",
    "        if atr_symbol_org[i] not in annot_list:\n",
    "            continue\n",
    "        else:\n",
    "            atr_sample_n.append(atr_sample_org[i])\n",
    "            atr_symbol_n.append(atr_symbol_org[i])\n",
    "    atr_sample = np.array(atr_sample_n)\n",
    "    atr_symbol = np.array(atr_symbol_n)\n",
    "\n",
    "    print(\"\\nAnotacijų pasiskirstymas po anotacijų valymo:\")\n",
    "    smb_lst = Counter(atr_symbol)\n",
    "    print(dict(smb_lst))\n",
    "    print()\n",
    "    # dict_array = make_dict_array(atr_sample,atr_symbol)\n",
    "    # print_dict_array(dict_array)\n",
    "\n",
    "    # Anotacijas stambinam į makro anotacijas\n",
    "    for i in range(len(atr_symbol)):\n",
    "        if atr_symbol[i] in annot_grouping:\n",
    "            atr_symbol[i] = annot_grouping[atr_symbol[i]]\n",
    "\n",
    "    print(\"Makro anotacijų pasiskirstymas:\")\n",
    "    smb_lst = Counter(atr_symbol)\n",
    "    print(dict(smb_lst))\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample, atr_symbol)\n",
    "    # print_dict_array(dict_array)\n",
    "\n",
    "# -------------------------------------- Sudaliname įrašus ir anotacijas į n dalių ir įrašome į diską\n",
    "    \n",
    "    n = 3 # dalių, į kurias daliname įrašus, skaičius\n",
    "    # signl_len = 10 # testavimui\n",
    "    smb_lst_suminis = {'N': 0, 'S': 0, 'V': 0, 'F':0, 'U':0, '~':0 } # testavimui\n",
    "    \n",
    "    # Pasiruošimas\n",
    "    len_sub_record = signl_len//n # will be assigned the value of the integer quotient of dividing len_sign by n\n",
    "    # print(n, signl_len, len_sub_record, len_sub_record*n)\n",
    "\n",
    "    # Pasiruošiame įrašų dalinimui triukšmų lentelę\n",
    "    # noise_table = convert_noise_table(noise_table_init, len_sub_record)\n",
    "    # if (record_nr == 100):\n",
    "    #     for elem in noise_table:\n",
    "    #         print(elem)\n",
    "\n",
    "    print(\"\\nĮrašo ir anotacijų dalijimas į n dalių\")\n",
    "    # Ciklas per n sub_records\n",
    "    for sub_recId in range(n):\n",
    "        print('\\nsub_recId:', sub_recId, \"Įrašo ilgis:\", len_sub_record)\n",
    "        lowerIndex = len_sub_record*sub_recId\n",
    "        upperIndex = len_sub_record*(sub_recId+1) - 1\n",
    "        # print('lowerIndex:', lowerIndex, 'upperIndex:', upperIndex, 'upperIndex-lowerIndex+1:', upperIndex-lowerIndex+1)\n",
    "\n",
    "        # deviding signal array\n",
    "        sub_record = np.empty(len_sub_record)\n",
    "        sub_record = signl[lowerIndex:upperIndex+1]\n",
    "        # print(\"len of sub_record:\", len(sub_record))\n",
    "\n",
    "        # Suformuojame padalinto EKG įrašo failo vardą (pvz. iš '100' padarome 10001.001) \n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        rec_ext = '{:03d}'.format(sub_recId+1)\n",
    "        file_name = str(record_nr) + rec_sub + '.' + rec_ext\n",
    "\n",
    "        # Įrašome suformuotą sub_record į duomenų aplanką\n",
    "        file_path = Path(rec_dir, file_name)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            np.save(f, sub_record)\n",
    "        # print('file_path:', file_path)\n",
    "        \n",
    "        # deviding annotation array\n",
    "        sub_atr_sample = []\n",
    "        sub_atr_symbol = []\n",
    "        for i in range(len(atr_sample)):\n",
    "            if (atr_sample[i] >= lowerIndex) & (atr_sample[i] < upperIndex):\n",
    "                sub_atr_sample.append(atr_sample[i] - lowerIndex)\n",
    "                sub_atr_symbol.append(atr_symbol[i])\n",
    "\n",
    "        counter_obj = Counter(sub_atr_symbol) \n",
    "        annot_items = counter_obj.items()\n",
    "\n",
    "        # testavimui\n",
    "        print(\"Makro anotacijų pasiskirstymas:\")\n",
    "        dict_obj = dict(counter_obj)\n",
    "        print(dict_obj)\n",
    "        # print()\n",
    "        for key in dict_obj:\n",
    "            # smb = elem[0]\n",
    "            val = dict_obj[key]\n",
    "            smb_lst_suminis[key] = smb_lst_suminis[key] + val\n",
    "        print('smb_lst_suminis:', smb_lst_suminis)    \n",
    "        # print()\n",
    "\n",
    "        # Analizei taip pat sudalijame į dalis taip pat ir originalius atributus,\n",
    "        # kurie nėra išvalyti nuo tarnybinių anotacijų\n",
    "\n",
    "        # sub_atr_sample_org = []\n",
    "        # sub_atr_symbol_org = []\n",
    "        # for i in range(len(atr_sample_org)):\n",
    "        #     if (atr_sample_org[i] >= lowerIndex) & (atr_sample_org[i] < upperIndex):\n",
    "        #         sub_atr_sample_org.append(atr_sample_org[i] - lowerIndex)\n",
    "        #         sub_atr_symbol_org.append(atr_symbol_org[i])\n",
    "\n",
    "        # counter_obj = Counter(sub_atr_symbol_org) \n",
    "        # annot_items = counter_obj.items()\n",
    "\n",
    "        # testavimui\n",
    "        # print(\"\\nVisų anotacijų pasiskirstymas:\")\n",
    "        # dict_obj = dict(counter_obj)\n",
    "        # print(dict_obj)\n",
    "        # dict_array = make_dict_array(sub_atr_sample_org,sub_atr_symbol_org)\n",
    "        # print_dict_array(dict_array, incl = ['~'])\n",
    "        # print()\n",
    "\n",
    "        # for key in dict_obj:\n",
    "        #     val = dict_obj[key]\n",
    "        #     smb_lst_suminis[key] = smb_lst_suminis[key] + val\n",
    "        # print('smb_lst_suminis:', smb_lst_suminis)    \n",
    "        # print()\n",
    "\n",
    "\n",
    "        # Paruošiame informaciją json failui\n",
    "\n",
    "        recordingId = str(record_nr) + rec_sub\n",
    "\n",
    "        rpeaks = []\n",
    "        for idx in range(len(sub_atr_sample)):\n",
    "            elem = {\"sampleIndex\": int(sub_atr_sample[idx]),\n",
    "                    \"annotationValue\": sub_atr_symbol[idx]}\n",
    "            rpeaks.append(elem)    \n",
    "        print('rpeaks length:', len(rpeaks))\n",
    "\n",
    "        # noises = get_noise_intervals(noise_table, recordingId)\n",
    "        noises = get_noise_spans(sub_atr_sample, sub_atr_symbol)\n",
    "        print('noises:', noises)\n",
    "\n",
    "        json_data = {\n",
    "            'recordingId': recordingId,\n",
    "            \"userId\": str(record_nr),\n",
    "            \"rpeakAnnotationCounts\": dict(annot_items),\n",
    "            \"noises\": noises,\n",
    "            \"rpeaks\": rpeaks \n",
    "        }\n",
    "\n",
    "        # Įrašome json failą su įrašo atributais\n",
    "        file_path = Path(rec_dir, file_name + '.json')\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(json_data, f)\n",
    "\n",
    "    print('smb_lst_suminis:', smb_lst_suminis)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------  SKAITYMO TESTAS \n",
    "\n",
    "print(\"\\nKontrolinis skaitymas\") \n",
    "\n",
    "# Kontrolinis  skaitymas\n",
    "\n",
    "for sub_recId in range(n):\n",
    "    rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "    rec_ext = '{:03d}'.format(sub_recId+1)\n",
    "    file_name = str(record_nr) + rec_sub + '.' + rec_ext\n",
    "   \n",
    "    # Įrašas\n",
    "    file_path = Path(rec_dir, file_name)\n",
    "    # print('\\nfile_path:', file_path)\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        sign_loaded = np.load(f) \n",
    "        # print(sign_loaded[:10])\n",
    "        # print('sign_loaded', sign_loaded.shape)\n",
    "   \n",
    "    # json\n",
    "    # Nuskaitome gydytojo koreguotus EKG įrašo atributus iš įrašo json \n",
    "    df_rpeaks = zive_read_df_rpeaks(rec_dir, file_name)\n",
    "    rpeaks_from_json = df_rpeaks['sampleIndex'].to_numpy()\n",
    "    symbols_from_json = df_rpeaks['annotationValue'].to_numpy()\n",
    "    # print(rpeaks_from_json[:20], symbols_from_json[:20])\n",
    "\n",
    "    print(\"Makro anotacijų pasiskirstymas. Variantas iš json failo:\")\n",
    "    smb_lst = Counter(symbols_from_json)\n",
    "    # print(dict(smb_lst))\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample,atr_symbol)\n",
    "    # print_dict_array(dict_array)\n",
    "\n",
    "\n",
    "print(\"\\nPabaiga.............\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paruošiame šabloną comments.csv failui\n",
    "# pvz.\n",
    "# filename,userId,recordingId,nesutmp,quality,comment\n",
    "# 1626934.963,0,0,\"Kokybė puiki, išskyrus pabaigą\"\n",
    "\n",
    "dict_array = []\n",
    "for record_nr in records_nr:\n",
    "    # print(record_nr)\n",
    "    for sub_recId in range(n):\n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        recordingId = str(record_nr) + rec_sub\n",
    "        rec_ext = '{:03d}'.format(sub_recId+1)\n",
    "        file_name = recordingId + '.' + rec_ext\n",
    "        elem = {'filename':file_name,  'userId': str(record_nr), 'recId': recordingId, 'nesutmp': 0, 'quality': 0, 'comment': ''}\n",
    "        dict_array.append(elem)\n",
    "\n",
    "df = pd.DataFrame(dict_array)\n",
    "print(df.head(5))\n",
    "file_name = 'comments_sablonas.csv'\n",
    "file_path = Path(rec_dir, file_name)\n",
    "df.to_csv(file_path, index=False)\n",
    "print(\"Šablonas įrašytas į: \", file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dar vienas bandymas surinkti triukšmų intervalus, šį kartą pagal `~`\n",
    "\n",
    "# Testavimui\n",
    "records_nr = np.array([116])\n",
    "\n",
    "for record_nr in records_nr:\n",
    "\n",
    "# ----------------------------------------------- Nuskaitome įrašą\n",
    "    subject_path = f'{db_path_mit}/{record_nr}'\n",
    "    # ic(subject_path)\n",
    "\n",
    "    record = wfdb.rdrecord(subject_path, sampfrom=0,channels=[0], physical=True)\n",
    "    signl_raw = record.p_signal[:,0]\n",
    "    # print(sign_raw[:20])\n",
    "\n",
    "    len_signl_raw = signl_raw.shape[0]\n",
    "    print(\"\\n\")\n",
    "    print(f\"Pacientas iš MIT: {record_nr}  Reikšmių: {len_signl_raw}\")\n",
    "\n",
    "    ann = wfdb.rdann(subject_path, 'atr', sampfrom=0, sampto=None, shift_samps=False)\n",
    "    \n",
    "    print(\"\\nAnnotation object:\")\n",
    "    print(type(ann.sample))\n",
    "    print(type(ann.symbol))\n",
    "    pairs = get_noise_spans(list(ann.sample), ann.symbol)\n",
    "    print(pairs)\n",
    "    # for pair in pairs:\n",
    "    #     pair[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triukšmų vietų perskaičiavimas - testas\n",
    "# Naudojamas atvejui, kai naudotos pažymėtos vietos iš: Įrašų aprašymai\n",
    "# From <https://archive.physionet.org/physiobank/database/html/mitdbdir/records.htm> \n",
    "# ir suvęstos rankiniu būdu į 'noise table'\n",
    "# Dabar šis variantas nenaudojamas, vietoj jo naudojamas automatinis su žymėmis `~`\n",
    "\n",
    "def convert_noise_table(noise_table_init, len_sub_record): \n",
    "# perdaro pradinę informaciją apie triukšmus gautą originaliems\n",
    "# MIT įrašams į informaciją, pritaikytą resamplintams įrašams ir\n",
    "# padalintiems į kelias dalis\n",
    "\n",
    "    noise_table = []\n",
    "\n",
    "    for elem in noise_table_init:\n",
    "        # print(elem)\n",
    "        noise_start = datetime.timedelta(minutes=elem['noise_min'], seconds=elem['noise_sec'])\n",
    "        start_seconds = noise_start.total_seconds()\n",
    "        start_samples = ((360*start_seconds)*sant)\n",
    "\n",
    "        # print(start_samples, len_sub_record)\n",
    "        q, r = divmod(start_samples, len_sub_record)\n",
    "        startIndex = int(r)\n",
    "        duration = int(elem['duration']*200)\n",
    "        endIndex = startIndex + duration\n",
    "        sub_recId = int(q)\n",
    "        # print(f\"rec: {elem['rec']}  sub_recId: {sub_recId+1} startIndex: {startIndex} endIndex: {endIndex}\")\n",
    "\n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        new_rec = {'rec': str(elem['rec']) + rec_sub, 'startIndex': startIndex, 'endIndex': endIndex }\n",
    "        noise_table.append(new_rec)\n",
    "    return noise_table\n",
    "\n",
    "def get_noise_intervals(noise_table, recordingId):\n",
    "    # print(recordingId)\n",
    "    filtered_list = [item for item in noise_table if item['rec'] == recordingId]\n",
    "    noise_intervals = []\n",
    "    for elem in filtered_list:\n",
    "        row = {\n",
    "            \"startIndex\": int(elem['startIndex']),\n",
    "            \"endIndex\":  int(elem['endIndex'])\n",
    "        }\n",
    "        noise_intervals.append(row)\n",
    "    return noise_intervals\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "noise_table_init = [\n",
    "    # rec 100 - švarus\n",
    "    {'rec':101, 'noise_min': 1, 'noise_sec': 48, 'duration': 10 },\n",
    "    {'rec':101, 'noise_min': 5, 'noise_sec': 13, 'duration': 10 },\n",
    "    \n",
    "    # rec 102 - švarus\n",
    "    # rec 103 - švarus\n",
    "\n",
    "    {'rec':104, 'noise_min': 5, 'noise_sec': 13, 'duration': 10 },\n",
    "    {'rec':104, 'noise_min': 6, 'noise_sec': 17, 'duration': 10 },\n",
    "    \n",
    "    {'rec':105, 'noise_min': 22, 'noise_sec': 2, 'duration': 10 },\n",
    "    {'rec':105, 'noise_min': 27, 'noise_sec': 27, 'duration': 10 },\n",
    "    {'rec':105, 'noise_min': 28, 'noise_sec': 8, 'duration': 10 },\n",
    "    {'rec':105, 'noise_min': 29, 'noise_sec': 7, 'duration': 10 },\n",
    "\n",
    "    # rec 106 - švarus\n",
    "    {'rec':107, 'noise_min': 20, 'noise_sec': 38, 'duration': 10 },\n",
    "    \n",
    "    {'rec':108, 'noise_min': 28, 'noise_sec': 10, 'duration': 10 }, # triukšmingas\n",
    "    {'rec':108, 'noise_min': 29, 'noise_sec': 0, 'duration': 10 },\n",
    "    \n",
    "    {'rec':109, 'noise_min': 5, 'noise_sec': 27, 'duration': 10 },\n",
    "    {'rec':109, 'noise_min': 26, 'noise_sec': 9, 'duration': 10 },\n",
    "    \n",
    "    {'rec':111, 'noise_min': 3, 'noise_sec': 52, 'duration': 10 },\n",
    "    {'rec':111, 'noise_min': 15, 'noise_sec': 41, 'duration': 10 },\n",
    "    {'rec':111, 'noise_min': 19, 'noise_sec': 54, 'duration': 10 },\n",
    "    {'rec':111, 'noise_min': 27, 'noise_sec': 2, 'duration': 10 },\n",
    "    \n",
    "    # rec 112 - švarus\n",
    "    # rec 113 - švarus\n",
    "    {'rec':114, 'noise_min': 20, 'noise_sec': 2, 'duration': 10 },\n",
    "    # rec 115 - švarus\n",
    "    {'rec':116, 'noise_min': 16, 'noise_sec': 37, 'duration': 10 },\n",
    "    {'rec':116, 'noise_min': 23, 'noise_sec': 8, 'duration': 10 },\n",
    "\n",
    "    {'rec':117, 'noise_min': 11, 'noise_sec': 58, 'duration': 10 },\n",
    "\n",
    "    {'rec':118, 'noise_min': 8, 'noise_sec': 31, 'duration': 10 },\n",
    "    {'rec':118, 'noise_min': 26, 'noise_sec': 48, 'duration': 10 },\n",
    "\n",
    "    {'rec':119, 'noise_min': 20, 'noise_sec': 5, 'duration': 10 },\n",
    "    {'rec':119, 'noise_min': 25, 'noise_sec': 33, 'duration': 10 },\n",
    "\n",
    "    {'rec':121, 'noise_min': 24, 'noise_sec': 32, 'duration': 10 },\n",
    "    {'rec':121, 'noise_min': 26, 'noise_sec': 1, 'duration': 10 },\n",
    "    \n",
    "    # rec 122 - švarus\n",
    "    # rec 123 - švarus\n",
    "    # rec 124 - švarus\n",
    "\n",
    "    {'rec':200, 'noise_min': 5, 'noise_sec': 38, 'duration': 10 },\n",
    "    {'rec':200, 'noise_min': 20, 'noise_sec': 52, 'duration': 11 },\n",
    "    {'rec':201, 'noise_min': 18, 'noise_sec': 14, 'duration': 10 },\n",
    "    # rec 202 - švarus\n",
    "\n",
    "    {'rec':203, 'noise_min': 15, 'noise_sec': 2, 'duration': 10 },\n",
    "    {'rec':203, 'noise_min': 23, 'noise_sec': 25, 'duration': 10 },\n",
    "    {'rec':203, 'noise_min': 24, 'noise_sec': 46, 'duration': 10 },\n",
    "    # rec 205 - švarus\n",
    "\n",
    "    {'rec':207, 'noise_min': 5, 'noise_sec': 19, 'duration': 10 },\n",
    "    {'rec':207, 'noise_min': 6, 'noise_sec': 56, 'duration': 10 },\n",
    "\n",
    "    {'rec':208, 'noise_min': 14, 'noise_sec': 57, 'duration': 10 },\n",
    "    {'rec':208, 'noise_min': 21, 'noise_sec': 6, 'duration': 10 },\n",
    "    {'rec':208, 'noise_min': 23, 'noise_sec': 0, 'duration': 10 },\n",
    "\n",
    "    {'rec':209, 'noise_min': 5, 'noise_sec': 50, 'duration': 10 },\n",
    "    {'rec':209, 'noise_min': 28, 'noise_sec': 17, 'duration': 10 },\n",
    "\n",
    "    {'rec':210, 'noise_min': 3, 'noise_sec': 47, 'duration': 10 },\n",
    "    {'rec':210, 'noise_min': 15, 'noise_sec': 55, 'duration': 10 },\n",
    "\n",
    "    {'rec':212, 'noise_min': 18, 'noise_sec': 42, 'duration': 10 },\n",
    "    {'rec':212, 'noise_min': 26, 'noise_sec': 45, 'duration': 10 },\n",
    "\n",
    "    # rec 213 - švarus\n",
    "    # rec 214 - švarus\n",
    "\n",
    "    {'rec':215, 'noise_min': 3, 'noise_sec': 11, 'duration': 10 },\n",
    "\n",
    "    {'rec':217, 'noise_min': 14, 'noise_sec': 1, 'duration': 10 },\n",
    "    # rec 219 - švarus, Atrial fibrillation\n",
    "    # rec 220 - švarus\n",
    "    \n",
    "    {'rec':221, 'noise_min': 19, 'noise_sec': 42, 'duration': 10 },\n",
    "   \n",
    "    {'rec':222, 'noise_min': 24, 'noise_sec': 43, 'duration': 10 },\n",
    "\n",
    "    # rec 223 - švarus\n",
    "\n",
    "    {'rec':228, 'noise_min': 4, 'noise_sec': 35, 'duration': 10 },\n",
    "    {'rec':228, 'noise_min': 20, 'noise_sec': 8, 'duration': 10 },\n",
    "    # rec 230 - švarus\n",
    "    # rec 231 - švarus\n",
    "\n",
    "    {'rec':232, 'noise_min': 0, 'noise_sec': 58, 'duration': 10 },\n",
    "    {'rec':232, 'noise_min': 11, 'noise_sec': 51, 'duration': 10 },\n",
    "    # rec 233 - švarus\n",
    "\n",
    "    {'rec':234, 'noise_min': 6, 'noise_sec': 37, 'duration': 10 },\n",
    "    {'rec':234, 'noise_min': 23, 'noise_sec': 17, 'duration': 10 },\n",
    "]\n",
    "\n",
    "print(\"\\nTestavimas naudojant noise table\")\n",
    "\n",
    "noise_table = convert_noise_table(noise_table_init, len_sub_record)\n",
    "for elem in noise_table:\n",
    "    print(elem)\n",
    "\n",
    "for record_nr in records_nr:\n",
    "    # print(record_nr)\n",
    "    for sub_recId in range(n):\n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        recordingId = str(record_nr) + rec_sub\n",
    "        noise_intervals = get_noise_intervals(noise_table, recordingId)\n",
    "        if bool(noise_intervals) != False:\n",
    "            print(noise_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testas kokybės anotacijoms išgauti - nepasisekęs, nes kokybės anotacijos sq_ann = ann.aux_note tuščios,\n",
    "# paaiškėjo, kad lightwave naudoja `~`\n",
    "\n",
    "def get_orig_sample_from_time(minutes, seconds):\n",
    "    noise_start = datetime.timedelta(minutes=minutes, seconds=seconds)\n",
    "    start_seconds = noise_start.total_seconds()\n",
    "    start_samples = int(360*start_seconds)\n",
    "    return start_samples\n",
    "\n",
    "def get_noise_place(atr_sample_org, atr_symbol_org, sample):\n",
    "    for idx in range(len(atr_sample_org)):\n",
    "        if atr_sample_org[idx] >= sample:\n",
    "            place360 = atr_sample_org[idx] \n",
    "            place200 = (atr_sample_org[idx]*sant).astype(int)\n",
    "            symbol = atr_symbol_org[idx]\n",
    "            break\n",
    "    return place360, place200, symbol\n",
    "\n",
    "\n",
    "# Testavimui\n",
    "records_nr = np.array([116])\n",
    "\n",
    "for record_nr in records_nr:\n",
    "\n",
    "# ----------------------------------------------- Nuskaitome įrašą\n",
    "    subject_path = f'{db_path_mit}/{record_nr}'\n",
    "    # ic(subject_path)\n",
    "\n",
    "    record = wfdb.rdrecord(subject_path, sampfrom=0,channels=[0], physical=True)\n",
    "    signl_raw = record.p_signal[:,0]\n",
    "    # print(sign_raw[:20])\n",
    "\n",
    "    len_signl_raw = signl_raw.shape[0]\n",
    "    print(\"\\n\")\n",
    "    print(f\"Pacientas iš MIT: {record_nr}  Reikšmių: {len_signl_raw}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Nuskaitome originalaus įrašo anotacijas\n",
    "    # https://wfdb.readthedocs.io/en/latest/wfdb.html \n",
    "\n",
    "    # wfdb.io.rdann(record_name, extension, sampfrom=0, sampto=None, shift_samps=False, \n",
    "    # pn_dir=None, return_label_elements=['symbol'], summarize_labels=False)\n",
    "    # Read a WFDB annotation file record_name.extension and return an Annotation obj\n",
    "\n",
    "    ann = wfdb.rdann(subject_path, 'atr', sampfrom=0, sampto=None, shift_samps=False, \n",
    "            pn_dir=None, return_label_elements=['symbol'], summarize_labels=True)\n",
    "    \n",
    "    atr_sample_org = ann.sample\n",
    "    atr_symbol_org = np.array(ann.symbol)\n",
    "    \n",
    "    print(\"\\nAnotacijų pasiskirstymas originale:\")\n",
    "    smb_lst = Counter(atr_symbol_org)\n",
    "    print(dict(smb_lst))\n",
    "    print()\n",
    "\n",
    "\n",
    "    print(\"\\nKokybės anotacijos originale:\")\n",
    "    sq_ann = ann.aux_note\n",
    "    print(sq_ann[:20])\n",
    "    print('len(sq_ann):', len(sq_ann))\n",
    "\n",
    "\n",
    "    print(\"\\nKokybės anotacijų pasiskirstymas originale:\")\n",
    "    sq_ann_org = np.array(sq_ann)\n",
    "    smb_lst = Counter(sq_ann_org)\n",
    "    print(dict(smb_lst))\n",
    "    print()\n",
    "\n",
    "\n",
    "    smb_lst = Counter(atr_symbol_org)\n",
    "    print(\"\\nOriginalių anotacijų pasiskirstymas:\")\n",
    "    print(smb_lst)\n",
    "    print()\n",
    "    dict_array = make_dict_array(atr_sample_org,atr_symbol_org)\n",
    "    print_dict_array(dict_array)\n",
    "    \n",
    "\n",
    "note = '16:37 Noise, saturation in upper signal'\n",
    "sample = get_orig_sample_from_time(16, 37)\n",
    "print('\\n', note, 'start:', sample)\n",
    "place360, place200, symbol = get_noise_place(atr_sample_org, atr_symbol_org, sample)\n",
    "print('place360:', place360, 'place200:', place200, 'symbol:', symbol )\n",
    "\n",
    "\n",
    "note = '23:08 Noise, saturation in upper signal'\n",
    "sample = get_orig_sample_from_time(23, 8)\n",
    "print('\\n', note, 'start:', sample)\n",
    "place360, place200, symbol = get_noise_place(atr_sample_org, atr_symbol_org, sample)\n",
    "print('place360:', place360, 'place200:', place200, 'symbol:', symbol )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ecg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f36dab35816871602f0a4fffa6415a4e758bca001397bb3d9f7e90aab6637a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
