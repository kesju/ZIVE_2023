{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sukuriamas Zive duomenų analogas iš MIT duomenų\n",
      "OS in my system :  linux\n",
      "Bendras Zive duomenų aplankas:  /home/kesju/DI/DUOMENU_TVARKYMAS_2023\n",
      "MIT duomenų aplankas:  mit-bih-arrhythmia-database-1.0.0\n",
      "Pacientų įrašų sąrašas:\n",
      " [232]\n",
      "Aplankas, kur rašome MIT2ZIVE duomenis:\n",
      " records_npy_tst\n",
      "Pastaba: įrašai su nr. 102, 104, 107, ir 217 yra gauti iš pacientų su pacemakers ir yra praleisti\n",
      "207 paciento įrašas turi segmentus su ventricular flutter or fibrillation VF\n",
      "\n",
      "Diskretizavimo dažnis fs_mit:  360\n",
      "\n",
      "Aplankas transformuotiems duomenims:  records_npy_tst\n",
      "Directory '/home/kesju/DI/DUOMENU_TVARKYMAS_2023/records_npy_tst' already exists\n",
      "Diskretizavimo dažnis fs_zive:  200\n",
      "fs_zive/fs_mit = 0.56\n",
      "Paliekamos įrašuose anotacijos: ['N', 'L', 'R', 'e', 'j', 'A', 'a', 'J', 'S', 'V', 'E', 'F', 'Q', '~']\n",
      "Failas grupavimui į makroanotacijas: {'N': 'N', 'R': 'N', 'L': 'N', 'e': 'N', 'j': 'N', 'A': 'S', 'a': 'S', 'J': 'S', 'S': 'S', 'V': 'V', 'E': 'V', 'F': 'F', 'Q': 'U', 's': 's', 'f': 'f'}\n"
     ]
    }
   ],
   "source": [
    "# Skriptas sukuria zive duomenų analogą iš MIT duomenų, į sub-aplanką rec_dir įrašomi\n",
    "# transformuoti EKG įrašai *.npy ir anotacijų failai *.json.\n",
    "# Išeities duomenys MIT_BIH atsisiunčiami iš aplanko mit-bih-arrhythmia-database-1.0.0\n",
    "# https://archive.physionet.org/physiobank/database/html/mitdbdir/mitdbdir.htm\n",
    "# The recordings were digitized at 360 samples per second per channel with 11-bit\n",
    "# resolution over a 10 mV range. In most records, the upper signal (channel 0) is\n",
    "# a modified limb lead II (MLII), obtained by placing the electrodes on the chest.\n",
    "\n",
    "# Iš MIT reaguojame tik į anotacijas N,L,R,e,j,V,E,S,A,a,J,F,Q, visas kitas ignoruojame.\n",
    "# MIT2ZIVE duomenyse paliekame tik makroanotacijas: N,S,V,F,U. \n",
    "\n",
    "# Failai skaldomi į 3 dalis, recordId = 1,2,3, kad būtų panašaus ilgio, kauip Zive įrašai.\n",
    "\n",
    "# Programos planas:\n",
    "# Nuskaitome MIT-BIH ekg įrašą: channel = 0, skaitome mlvoltus\n",
    "# Anotacijų mapingas į N,V,S,F,U\n",
    "# Pakeičiame diskretizavimo dažnį iš 360 į 200 Hz\n",
    "# Perskaičiuojame anotacijos vietas\n",
    "# Padalijame įrašus į tris dalis\n",
    "# Įrašome ekg ir anotacijas zive formatu į diską\n",
    "# Suformuojame comments.csv failą, kuriame komentaruose nurodysime DS1, ar DS2 \n",
    "\n",
    "# //////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "# Waveform Database Software Package (WFDB) for Python\n",
    "# https://physionet.org/content/wfdb-python/4.1.0/\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neurokit2 as nk\n",
    "from neurokit2 import signal_resample\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "# from zive_util_vu import create_dir\n",
    "from mit_bih_util import create_dir\n",
    "\n",
    "def make_dict_array(atr_sample, atr_symbol):\n",
    "    array_of_dict = []\n",
    "    for sample, symbol in zip(atr_sample, atr_symbol):\n",
    "        d = {'sample': sample, 'symbol': symbol}\n",
    "        array_of_dict.append(d)\n",
    "    return array_of_dict   \n",
    "\n",
    "def print_dict_array(dict_array, incl = []):\n",
    "    for d in dict_array:\n",
    "        sample = d['sample']\n",
    "        symbol = d['symbol']\n",
    "        if bool(incl) == False:\n",
    "            if (symbol != 'N'):\n",
    "                print(f\"Sample: {sample}, Symbol: {symbol}\")    \n",
    "        else:\n",
    "            if (symbol in incl):\n",
    "                print(f\"Sample: {sample}, Symbol: {symbol}\")     \n",
    "\n",
    "def zive_read_file_1ch(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    a = np.fromfile(f, dtype=np.dtype('>i4'))\n",
    "    ADCmax=0x800000\n",
    "    Vref=2.5\n",
    "    b = (a - ADCmax/2)*2*Vref/ADCmax/3.10*1000\n",
    "    ecg_signal = b - np.mean(b)\n",
    "    return ecg_signal\n",
    "\n",
    "def zive_read_df_rpeaks(db_path, file_name):\n",
    "    file_path = Path(db_path, file_name + '.json')\n",
    "    with open(file_path,'r', encoding=\"utf8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    df_rpeaks = pd.json_normalize(data, record_path =['rpeaks'])\n",
    "    return df_rpeaks\n",
    "\n",
    "def find_f_l(sample, lst):\n",
    "    last_s_idx = -1\n",
    "    result = []\n",
    "\n",
    "    for i in sample:\n",
    "        if lst[i] == 's':\n",
    "            last_s_idx = i\n",
    "        elif lst[i] == 'f' and last_s_idx != -1 and i > last_s_idx:\n",
    "            result.append((last_s_idx, i))\n",
    "            last_s_idx = -1        \n",
    "    return result\n",
    "\n",
    "def print_noises_intervals(noises_intervals, fs):    \n",
    "    for dict_obj in noises_intervals:\n",
    "        start = dict_obj['startIndex']/fs\n",
    "        start_min = start//60\n",
    "        start_sec = start % 60\n",
    "\n",
    "        finish = dict_obj['endIndex']/fs\n",
    "        finish_min = finish//60\n",
    "        finish_sec = finish % 60\n",
    "        print(f\"start: {dict_obj['startIndex']} {start_min:.2f} min {start_sec:.1f} sec finish: {dict_obj['endIndex']} {finish_min:.2f} min {finish_sec:.1f} sec\")    \n",
    "        # print(f\"start: {start_min:.2f} min {start_sec:.1f} sec finish: {finish_min:.2f} min {finish_sec:.1f} sec\")    \n",
    " \n",
    "def get_noise_intervals(noise_pairs, atr_sample):    \n",
    "    noise_intervals = []\n",
    "    for elem in noise_pairs:\n",
    "        lowerIndex = elem[0]\n",
    "        start = atr_sample[lowerIndex]\n",
    "\n",
    "        upperLevel = elem[1]\n",
    "        end = atr_sample[upperLevel]\n",
    "\n",
    "        dict_obj = {'startIndex': start, 'endIndex': end}\n",
    "        noise_intervals.append(dict_obj)\n",
    "    return noise_intervals\n",
    " \n",
    "\n",
    "def get_noise_pairs(atr_symbol, ann_subtype):\n",
    "    # Susitvarkome su `~`\n",
    "    occurrences = [i for i in range(len(atr_symbol)) if atr_symbol[i] == '~']\n",
    "    # print(occurrences)\n",
    "    atr_symbol_trs = atr_symbol.copy()\n",
    "\n",
    "    # Paverčiame '~' į 's' (startIndex) arba 'f' (finish)\n",
    "    for idx in occurrences:\n",
    "        if ann_subtype[idx] == 1 or ann_subtype[idx] == 3:\n",
    "            atr_symbol_trs[idx] = 's'\n",
    "        elif ann_subtype[idx] == 0 or ann_subtype[idx] == 2:\n",
    "            atr_symbol_trs[idx] = 'f'\n",
    "        else:\n",
    "            atr_symbol_trs[idx] = ''\n",
    "\n",
    "    # Ištraukiame įrašų triukšmų anotacijas (pradžias ir pabaigas)\n",
    "    noises_pairs = find_f_l(occurrences, atr_symbol_trs)\n",
    "    return noises_pairs, atr_symbol_trs\n",
    "\n",
    "def split_noise_intervals_into_3(noises_intervals, range_limits):\n",
    "    \n",
    "    range1_max = range_limits[0]\n",
    "    range2_max = range_limits[1]\n",
    "    range3_max = range_limits[2]\n",
    "\n",
    "    range1 = []\n",
    "    range2 = []\n",
    "    range3 = []\n",
    "\n",
    "    for interval in noises_intervals:\n",
    "        if interval['startIndex'] <= range1_max:\n",
    "            if interval['endIndex'] <= range1_max:\n",
    "                range1.append(interval)\n",
    "            else:\n",
    "                range1.append({'startIndex': interval['startIndex'], 'endIndex': range1_max})\n",
    "                if interval['endIndex'] <= range2_max:\n",
    "                    range2.append({'startIndex': range1_max, 'endIndex': interval['endIndex']})\n",
    "                else:\n",
    "                    range2.append({'startIndex': range1_max, 'endIndex': range2_max})\n",
    "                    if interval['endIndex'] <= range3_max:\n",
    "                        range3.append({'startIndex': range2_max, 'endIndex': interval['endIndex']})\n",
    "                    else:\n",
    "                        raise ValueError('Interval overlaps range limits')\n",
    "        elif interval['startIndex'] <= range2_max:\n",
    "            if interval['endIndex'] <= range2_max:\n",
    "                range2.append(interval)\n",
    "            else:\n",
    "                range2.append({'startIndex': interval['startIndex'], 'endIndex': range2_max})\n",
    "                if interval['endIndex'] <= range3_max:\n",
    "                    range3.append({'startIndex': range2_max, 'endIndex': interval['endIndex']})\n",
    "                else:\n",
    "                    raise ValueError('Interval overlaps range limits')\n",
    "        elif interval['startIndex'] <= range3_max:\n",
    "            if interval['endIndex'] <= range3_max:\n",
    "                range3.append(interval)\n",
    "            else:\n",
    "                range3.append({'startIndex': interval['startIndex'], 'endIndex': range3_max})\n",
    "                raise ValueError('Interval overlaps range limits')\n",
    "        else:\n",
    "            raise ValueError('Interval exceeds range limits')\n",
    "\n",
    "    ranges_all = [range1, range2, range3]\n",
    "        \n",
    "    #  Convert values to int and displace\n",
    "    for i in range(len(ranges_all)):\n",
    "        displacement = range_limits[i] - range_limits[0]\n",
    "        for j in range(len(ranges_all[i])):\n",
    "            ranges_all[i][j]['startIndex'] = int(ranges_all[i][j]['startIndex'] - displacement)\n",
    "            ranges_all[i][j]['endIndex'] = int(ranges_all[i][j]['endIndex'] - displacement)        \n",
    "    return ranges_all\n",
    "\n",
    "def AnalyseHeartrate(ecg_signal_df):\n",
    "    _, rpeaks = nk.ecg_peaks(ecg_signal_df['orig'], sampling_rate=200, method=\"neurokit\", correct_artifacts=False)\n",
    "    ret = {'rpeaks':rpeaks['ECG_R_Peaks'].tolist()}\n",
    "    return ret \n",
    "\n",
    "\n",
    "print(\"\\nSukuriamas Zive duomenų analogas iš MIT duomenų\")\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\\\DI\\\\DUOM_2022_RUDUO'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/DUOMENU_TVARKYMAS_2023'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Aplankas su MIT-BIH duomenų rinkiniu\n",
    "db_folder_mit = 'mit-bih-arrhythmia-database-1.0.0'\n",
    "\n",
    "#  Aplankas, kur rašome MIT2ZIVE duomenis\n",
    "db_folder_mit2zive = 'records_npy_tst'\n",
    "\n",
    "\n",
    "# Užduodamas pacientų įrašų sąrašas\n",
    "# Testavimui\n",
    "records_nr = np.array([116])\n",
    "# records_nr = np.array([124,209,228])\n",
    "\n",
    "records_nr = np.array(\n",
    "[100, 101, 103, 105, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124,\n",
    "200, 201, 202, 203, 205, 208, 209, 210, 212, 213, 214, 215, 219, 220, 221, 222, 223, 228, 230, 231,\n",
    "232, 233, 234])\n",
    "\n",
    "# records_nr = np.array([232])\n",
    "\n",
    "# MIT_BIH duomenų diskretizavimo dažnumas\n",
    "fs_mit = 360\n",
    "\n",
    "\n",
    "# ////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Nuoroda į MIT-BIH duomenų rinkinį\n",
    "db_path_mit = Path(Duomenu_aplankas, db_folder_mit)\n",
    "\n",
    "print(\"Bendras Zive duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"MIT duomenų aplankas: \", db_folder_mit)\n",
    "print(\"Pacientų įrašų sąrašas:\\n\",records_nr)\n",
    "print(\"Aplankas, kur rašome MIT2ZIVE duomenis:\\n\", db_folder_mit2zive)\n",
    "\n",
    "print(\"Pastaba: įrašai su nr. 102, 104, 107, ir 217 yra gauti iš pacientų su pacemakers ir yra praleisti\")\n",
    "print(\"207 paciento įrašas turi segmentus su ventricular flutter or fibrillation VF\")\n",
    "print(\"\\nDiskretizavimo dažnis fs_mit: \", fs_mit)\n",
    "\n",
    "\n",
    "# //////////////// Nurodomi MIT2ZIVE parametrai ////////////////////////////////\n",
    "\n",
    "\n",
    "# MIT2ZIVE duomenų diskretizavimo dažnumas\n",
    "fs_zive = 200 # diskretizavimo dažnumas\n",
    "\n",
    "# Neignoruojamų anotacijų sąrašas\n",
    "annot_list = ['N','L','R','e','j','A','a','J','S','V','E','F','Q','~']\n",
    "\n",
    "# Failai pūpsnių makro anotacijų formavimui\n",
    "annot_grouping = {\n",
    "'N':'N','R':'N', 'L':'N', 'e':'N', 'j':'N', 'A':'S','a':'S', 'J':'S', 'S':'S', 'V':'V', 'E':'V', 'F':'F','Q':'U', 's':'s', 'f':'f' }\n",
    "\n",
    "\n",
    "selected_beats = {'N':0, 'S':1, 'V':2, 'F':3, 'U':4}\n",
    "\n",
    "# ////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Nuoroda į MIT2ZIVE duomenų rinkinį\n",
    "# db_path_mit2zive = Path(Duomenu_aplankas, db_folder_mit2zive)\n",
    "\n",
    "# Nuoroda į aplanką MIT2ZIVE EKG įrašams (.npy) ir anotacijoms (.json)\n",
    "rec_dir = Path(Duomenu_aplankas, db_folder_mit2zive)\n",
    "\n",
    "sant = fs_zive/fs_mit\n",
    "\n",
    "print(\"\\nAplankas transformuotiems duomenims: \", db_folder_mit2zive)\n",
    "\n",
    "# Sukūriame aplanką transformuotiems iš MIT į Zive formatą duomenims\n",
    "create_dir(rec_dir)\n",
    "\n",
    "print(\"Diskretizavimo dažnis fs_zive: \", fs_zive)\n",
    "print(f\"fs_zive/fs_mit = {sant:.2f}\")\n",
    "\n",
    "print(\"Paliekamos įrašuose anotacijos:\", annot_list)\n",
    "print(\"Failas grupavimui į makroanotacijas:\", annot_grouping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Pacientas iš MIT: 232  Reikšmių: 650000\n",
      "len(atr_sample_org): 1816\n",
      "len(ann.subtype): 1816\n",
      "\n",
      "Anotacijų pasiskirstymas originale:\n",
      "{'+': 1, 'R': 397, 'A': 1382, 's': 12, 'f': 23, 'j': 1}\n",
      "\n",
      "Pacientas Zive rinkiniui: 232  Resamplintas. Reikšmių: 361111\n",
      "start: 1416 0.00 min 7.1 sec finish: 14253 1.00 min 11.3 sec\n",
      "start: 16752 1.00 min 23.8 sec finish: 18006 1.00 min 30.0 sec\n",
      "start: 55332 4.00 min 36.7 sec finish: 56200 4.00 min 41.0 sec\n",
      "start: 67993 5.00 min 40.0 sec finish: 69922 5.00 min 49.6 sec\n",
      "start: 77702 6.00 min 28.5 sec finish: 77928 6.00 min 29.6 sec\n",
      "start: 135497 11.00 min 17.5 sec finish: 138280 11.00 min 31.4 sec\n",
      "start: 142295 11.00 min 51.5 sec finish: 146618 12.00 min 13.1 sec\n",
      "start: 266520 22.00 min 12.6 sec finish: 266908 22.00 min 14.5 sec\n",
      "start: 268724 22.00 min 23.6 sec finish: 269458 22.00 min 27.3 sec\n",
      "length of rpeaks from signal: 1842\n",
      "[   94   273   410   556   693   922  1058  1199  1281  1572  1704  1796\n",
      "  2038  2173  2302  2507  2640  2803  2881  2968  3103  3254  3602  3734\n",
      "  3880  4019  4163  4308  4447  4587  4754  4968  5155  5495  5720  5856\n",
      "  5998  6368  6503  6653  6799  6941  7082  7225  7369  7515  7663  7810\n",
      "  7956  8142  8249  8510  8738  8871  9015  9399  9535  9680  9825  9923\n",
      " 10130 10224 10496 10629 10774 10918 11059 11205 11579 11739 11978 12114\n",
      " 12259 12511 12626 12759 12906 13271 13404 13548 13690 13851 14085 14237\n",
      " 14501 14895 15028 15171 15311 15457 15602 15744 15885 16029 16175 16319\n",
      " 16544 16672 16810 16956]\n",
      "\n",
      "rpeaks iš mit: 1816\n",
      "[   42   272   409   555   921  1057  1197  1416  1571  1703  2037  2171\n",
      "  2506  2639  2967  3102  3252  3601  3733  3878  4017  4162  4307  4446\n",
      "  4586  4967  5494  5719  5855  5997  6367  6502  6652  6798  6940  7081\n",
      "  7223  7368  7514  7662  7810  7954  8509  8737  8870  9013  9398  9534\n",
      "  9678  9824 10223 10495 10627 10772 10917 11058 11203 11737 11977 12113\n",
      " 12258 12625 12758 12905 13270 13403 13546 13688 14084 14253 14500 14894\n",
      " 15027 15170 15310 15456 15601 15742 15883 16028 16174 16318 16671 16752\n",
      " 16809 16955 17099 17385 17519 17663 18006 18043 18182 18329 18473 18617\n",
      " 18760 19058 19197 19347]\n",
      "\n",
      "patikslinti rpeaks iš mit: 1816\n",
      "[   42   273   410   556   922  1058  1199  1416  1572  1704  2038  2173\n",
      "  2507  2640  2968  3103  3254  3602  3734  3880  4019  4163  4308  4447\n",
      "  4587  4968  5495  5720  5856  5998  6368  6503  6653  6799  6941  7082\n",
      "  7225  7369  7515  7663  7810  7956  8510  8738  8871  9015  9399  9535\n",
      "  9680  9825 10224 10496 10629 10774 10918 11059 11205 11739 11978 12114\n",
      " 12259 12626 12759 12906 13271 13404 13548 13690 14085 14253 14501 14895\n",
      " 15028 15171 15311 15457 15602 15744 15885 16029 16175 16319 16672 16752\n",
      " 16810 16956 17100 17386 17520 17665 18006 18044 18183 18330 18474 18618\n",
      " 18761 19059 19199 19348]\n",
      "Makro anotacijų pasiskirstymas:\n",
      "{'N': 398, 'S': 1382}\n",
      "\n",
      "len_sub_record: 120370\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ciklas per pacientų įrašus\n",
    "for record_nr in records_nr:\n",
    "\n",
    "\n",
    "# ------------------------------------------ Nuskaitome įrašą ir jo atributus\n",
    "# ---------------------------------------------------------------------------\n",
    "    subject_path = f'{db_path_mit}/{record_nr}'\n",
    "    # ic(subject_path)\n",
    "\n",
    "    # Įrašo skaitymo variantai\n",
    "    # sequence, fields = wfdb.rdsamp(subject_path, channels=[0])\n",
    "    # record = wfdb.rdrecord('sample-data/a103l')\n",
    "\n",
    "    # https://www.programmersought.com/article/28613723297/\n",
    "    \n",
    "    #  Variantas 1 - skaitmeninės reikšmės\n",
    "    # record = wfdb.rdrecord(subject_path, sampfrom=1,\n",
    "                                # channels=[0], physical=False)\n",
    "    # sign_raw = record.d_signal[:,0]\n",
    "\n",
    "    # Variantas 2 - fizinės reikšmės - perverstos į mV\n",
    "    \n",
    "    record = wfdb.rdrecord(subject_path, sampfrom=0,channels=[0], physical=True)\n",
    "    signl_raw = record.p_signal[:,0]\n",
    "    # print(sign_raw[:20])\n",
    "\n",
    "    # https://wfdb.readthedocs.io/en/latest/wfdb.html\n",
    "\n",
    "    len_signl_raw = signl_raw.shape[0]\n",
    "    print(\"\\n\")\n",
    "    print(f\"Pacientas iš MIT: {record_nr}  Reikšmių: {len_signl_raw}\")\n",
    "\n",
    "    # Eilutės galimam filtravimui\n",
    "    # sign_transf = sign_raw\n",
    "    # sign_transf = signal_filter(signal=sign_raw, sampling_rate=360,\n",
    "    #  lowcut=0.1, method=\"butterworth\", order=5)\n",
    "\n",
    "    # Nuskaitome originalaus įrašo anotacijas\n",
    "    # https://wfdb.readthedocs.io/en/latest/wfdb.html \n",
    "    ann = wfdb.rdann(subject_path, 'atr', sampfrom=0, sampto=None, shift_samps=False)\n",
    "    atr_sample_org = ann.sample\n",
    "    atr_symbol_org = np.array(ann.symbol)\n",
    "    print('len(atr_sample_org):', len(atr_sample_org))\n",
    "    ann_subtype = ann.subtype\n",
    "    print('len(ann.subtype):', len(ann.subtype))\n",
    "\n",
    "    noises_pairs_org, atr_symbol_trs = get_noise_pairs(atr_symbol_org, ann_subtype)\n",
    "    noises_intervals_org = get_noise_intervals(noises_pairs_org, atr_sample_org)\n",
    "    # for elem in noises_intervals_org:\n",
    "    #     print('noises_intervals_org:', elem)\n",
    "    # print_noises_intervals(noises_intervals_org, 360)\n",
    "    \n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample_org, atr_symbol_trs)\n",
    "    # print_dict_array(dict_array, incl = ['s', 'f'])\n",
    "\n",
    "\n",
    "    print(\"\\nAnotacijų pasiskirstymas originale:\")\n",
    "    smb_lst = Counter(atr_symbol_trs)\n",
    "    print(dict(smb_lst))\n",
    "    print()\n",
    "    \n",
    "\n",
    "\n",
    "# ------------------------------------ Resampling iš 360 Hz (MIT) į 200 Hz (Zive)\n",
    "# -------------------------------------------------------------------------------\n",
    "    signl = signal_resample(signl_raw, sampling_rate=fs_mit,\n",
    "                              desired_sampling_rate=200, method=\"numpy\")\n",
    "    # https://neurokit2.readthedocs.io/en/latest/_modules/neurokit2/signal/signal_resample.html\n",
    "\n",
    "    signl_len = signl.shape[0]\n",
    "    print(f\"Pacientas Zive rinkiniui: {record_nr}  Resamplintas. Reikšmių: {signl_len}\")\n",
    "    # print(signl[:20])\n",
    "\n",
    "    # Resampliname anotacijų vietas\n",
    "    atr_sample_rsp = (atr_sample_org*sant).astype(int)\n",
    "    # pastaba: po resampling atsiranda tik atr_sample_rsp, kuris pakeičia\n",
    "    # atr_sample_org. Tuo tarpu atr_symbol_org, ann_subtype išlieka tie patys\n",
    "\n",
    "    # Surandame resamplinto įrašo triukšmų intervalus\n",
    "    noises_pairs, atr_symbol_trs = get_noise_pairs(atr_symbol_org, ann_subtype)\n",
    "    noises_intervals = get_noise_intervals(noises_pairs, atr_sample_rsp)\n",
    "    print_noises_intervals(noises_intervals,200)\n",
    "\n",
    "    # print(\"\\nAnotacijų pasiskirstymas po resampling:\")\n",
    "    # smb_lst = Counter(atr_symbol_trs)\n",
    "    # print(dict(smb_lst))\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample_rsp,atr_symbol_trs)\n",
    "    # print_dict_array(dict_array, incl = ['s', 'f'])\n",
    "\n",
    "# --------------------------------- Patiksliname rpeaks su Neurokit 2\n",
    "# Tikslinama vieta tik tuo atveju, jei skirtumas su išeities pozicija\n",
    "# nesiskiria daugiau kaip 2.\n",
    " \n",
    "# Surandame rpeaks su Neurokit\n",
    "    ecg_signal_df = pd.DataFrame(signl, columns=['orig'])\n",
    "    analysis_results = AnalyseHeartrate(ecg_signal_df)\n",
    "    rpeaks_from_signal = analysis_results['rpeaks']\n",
    "    atr_sample_sign = np.array(rpeaks_from_signal)\n",
    "\n",
    "    print('length of rpeaks from signal:', len(atr_sample_sign))\n",
    "    # print(atr_sample_sign[:100])\n",
    "    print(f\"\\nrpeaks iš mit: {len(atr_sample_rsp)}\")  \n",
    "    # print(atr_sample_rsp[:100])\n",
    "\n",
    "    for i in range(len(atr_sample_sign)):\n",
    "        for j in range(len(atr_sample_rsp)):\n",
    "            if abs(atr_sample_sign[i] - atr_sample_rsp[j]) <= 2:\n",
    "                atr_sample_rsp[j] = atr_sample_sign[i]\n",
    "                break\n",
    "    print(f\"\\npatikslinti rpeaks iš mit: {len(atr_sample_rsp)}\")  \n",
    "    # print(atr_sample_rsp[:100])\n",
    "\n",
    "# ------------------------------ Anotacijas apvalome ir sukūriame makro anotacijas\n",
    "    # Paliekame tik užduotas anotacijas iš annot_list, visas kitas (tarnybines)\n",
    "    # Tarnybinės yra: `~`, '+', ir visos kitos\n",
    "    \n",
    "    atr_sample_n = []\n",
    "    atr_symbol_n = []\n",
    "    for i in range(atr_sample_rsp.shape[0]):\n",
    "        if atr_symbol_trs[i] not in annot_list:\n",
    "            continue\n",
    "        else:\n",
    "            atr_sample_n.append(atr_sample_rsp[i])\n",
    "            atr_symbol_n.append(atr_symbol_org[i])\n",
    "    atr_sample = np.array(atr_sample_n)\n",
    "    atr_symbol = np.array(atr_symbol_n)\n",
    "\n",
    "    # print(\"\\nAnotacijų pasiskirstymas po anotacijų valymo:\")\n",
    "    # smb_lst = Counter(atr_symbol)\n",
    "    # print(dict(smb_lst))\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample,atr_symbol)\n",
    "    # print_dict_array(dict_array)\n",
    "\n",
    "    # Anotacijas stambiname į makro anotacijas\n",
    "    for i in range(len(atr_symbol)):\n",
    "        if atr_symbol[i] in annot_grouping:\n",
    "            atr_symbol[i] = annot_grouping[atr_symbol[i]]\n",
    "\n",
    "    print(\"Makro anotacijų pasiskirstymas:\")\n",
    "    smb_lst = Counter(atr_symbol)\n",
    "    print(dict(smb_lst))\n",
    "    # print()\n",
    "    # dict_array = make_dict_array(atr_sample, atr_symbol)\n",
    "    # print_dict_array(dict_array)\n",
    "\n",
    "     \n",
    "# ------------------------------ Sudaliname įrašus ir anotacijas į n dalių ir įrašome į diską\n",
    "# -------------------------------------------------------------------------------------------   \n",
    "    n = 3 # dalių, į kurias daliname įrašus, skaičius\n",
    "\n",
    "    # Įrašų ilgis po padalinimo\n",
    "    len_sub_record = signl_len//n # will be assigned the value of the integer quotient\n",
    "    # of dividing len_sign by n\n",
    "\n",
    "    print('\\nlen_sub_record:', len_sub_record)\n",
    "    # print(n, signl_len, len_sub_record, len_sub_record*n)\n",
    "\n",
    "    # Padaliname į 3 dalis triukšmų intervalus\n",
    "    range_limits = [len_sub_record*i for i in range(1,4)]\n",
    "    noise_intervals = split_noise_intervals_into_3(noises_intervals, range_limits)\n",
    "    \n",
    "    # print(\"\\nTriukšmai po sudalijimo:\")\n",
    "    # dict_array = make_dict_array(atr_sample, atr_symbol)\n",
    "    # print_dict_array(dict_array, incl = ['s', 'f'])\n",
    "    \n",
    "    # signl_len = 10 # testavimui\n",
    "    smb_lst_suminis = {'N': 0, 'S': 0, 'V': 0, 'F':0, 'U':0, 's':0, 'f':0 } # testavimui\n",
    "    \n",
    "    # print(\"\\nĮrašo ir anotacijų dalijimas į n dalių\")\n",
    "    \n",
    "# -------------------------------------------------------------- Ciklas per n sub_records\n",
    "    for sub_recId in range(n):\n",
    "        # print('\\nsub_recId:', sub_recId, \"Įrašo ilgis:\", len_sub_record)\n",
    "        lowerIndex = len_sub_record*sub_recId\n",
    "        upperIndex = len_sub_record*(sub_recId+1) - 1\n",
    "        # print('lowerIndex:', lowerIndex, 'upperIndex:', upperIndex, 'upperIndex-lowerIndex+1:', upperIndex-lowerIndex+1)\n",
    "\n",
    "        # dividing signal array\n",
    "        sub_record = np.empty(len_sub_record)\n",
    "        sub_record = signl[lowerIndex:upperIndex+1]\n",
    "        # print(\"len of sub_record:\", len(sub_record))\n",
    "\n",
    "        # Suformuojame padalinto EKG įrašo failo vardą (pvz. iš '100' padarome 10001.001) \n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        rec_ext = '{:03d}'.format(sub_recId+1)\n",
    "        file_name = str(record_nr) + rec_sub + '.' + rec_ext\n",
    "\n",
    "        # Įrašome suformuotą sub_record į duomenų aplanką\n",
    "        file_path = Path(rec_dir, file_name)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            np.save(f, sub_record)\n",
    "        # print('file_path:', file_path)\n",
    "        \n",
    "        # deviding annotation array\n",
    "        sub_atr_sample = []\n",
    "        sub_atr_symbol = []\n",
    "        for i in range(len(atr_sample)):\n",
    "            if (atr_sample[i] >= lowerIndex) & (atr_sample[i] < upperIndex):\n",
    "                sub_atr_sample.append(atr_sample[i] - lowerIndex)\n",
    "                sub_atr_symbol.append(atr_symbol[i])\n",
    "\n",
    "        counter_obj = Counter(sub_atr_symbol) \n",
    "        annot_items = counter_obj.items()\n",
    "\n",
    "        # testavimui\n",
    "        # print(\"Makro anotacijų pasiskirstymas:\")\n",
    "        # dict_obj = dict(counter_obj)\n",
    "        # print(dict_obj)\n",
    "        # # print()\n",
    "        # for key in dict_obj:\n",
    "        #     val = dict_obj[key]\n",
    "        #     smb_lst_suminis[key] = smb_lst_suminis[key] + val\n",
    "        # print('smb_lst_suminis:', smb_lst_suminis)    \n",
    "        # print()\n",
    "        \n",
    "# ---------------------------------- Paruošiame informaciją json failui ir įrašome\n",
    "        recordingId = str(record_nr) + rec_sub\n",
    "\n",
    "        rpeaks = []\n",
    "        for idx in range(len(sub_atr_sample)):\n",
    "            elem = {\"sampleIndex\": int(sub_atr_sample[idx]),\n",
    "                    \"annotationValue\": sub_atr_symbol[idx]}\n",
    "            rpeaks.append(elem)    \n",
    "        # print('rpeaks length:', len(rpeaks))\n",
    "\n",
    "        json_data = {\n",
    "            'recordingId': recordingId,\n",
    "            \"userId\": str(record_nr),\n",
    "            \"rpeakAnnotationCounts\": dict(annot_items),\n",
    "            \"noises\": noise_intervals[sub_recId],\n",
    "            \"rpeaks\": rpeaks \n",
    "        }\n",
    "\n",
    "        # Įrašome json failą su įrašo atributais\n",
    "        file_path = Path(rec_dir, file_name + '.json')\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(json_data, f)\n",
    "\n",
    "    # print('smb_lst_suminis:', smb_lst_suminis)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    filename userId  recId  nesutmp  quality comment\n",
      "0  23201.001    232  23201        0        0        \n",
      "1  23202.002    232  23202        0        0        \n",
      "2  23203.003    232  23203        0        0        \n"
     ]
    }
   ],
   "source": [
    "# Paruošiame šabloną comments.csv failui\n",
    "# pvz.\n",
    "# filename,userId,recordingId,nesutmp,quality,comment\n",
    "# 1626934.963,0,0,\"Kokybė puiki, išskyrus pabaigą\"\n",
    "\n",
    "dict_array = []\n",
    "for record_nr in records_nr:\n",
    "    # print(record_nr)\n",
    "    for sub_recId in range(n):\n",
    "        rec_sub = '{:02d}'.format(sub_recId+1)\n",
    "        recordingId = str(record_nr) + rec_sub\n",
    "        rec_ext = '{:03d}'.format(sub_recId+1)\n",
    "        file_name = recordingId + '.' + rec_ext\n",
    "        elem = {'filename':file_name,  'userId': str(record_nr), 'recId': recordingId, 'nesutmp': 0, 'quality': 0, 'comment': ''}\n",
    "        dict_array.append(elem)\n",
    "\n",
    "df = pd.DataFrame(dict_array)\n",
    "print(df.head(5))\n",
    "file_name = 'comments_sablonas.csv'\n",
    "file_path = Path(rec_dir, file_name)\n",
    "# df.to_csv(file_path, index=False)\n",
    "# print(\"Šablonas įrašytas į: \", file_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ecg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f36dab35816871602f0a4fffa6415a4e758bca001397bb3d9f7e90aab6637a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
